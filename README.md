# End-to-end GAN-TTS architecture
A tensorflow implementation of GAN-TTS paper.
### Notes
- Text embeddings are generated by a tensorflow pre-trained BERT model.
- Linguistic features are not predicted by external models, but they are predicted by a feature net that works together with the generator and the discriminator. The feature net is a simple CBHG module, which takes a text embedding in input and outputs a tensor of linguistic features.
- The architecture is not trained yet, but you can explore the data flow and data dimensionality using the notebook [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/alexandruRopotica/E2E-GANTTS/blob/main/E2EGANTTS.ipynb).
### Papers
- [GAN-TTS](https://arxiv.org/abs/1909.11646) - Used to implement generator and discriminator
- [Tacotron](https://arxiv.org/abs/1703.10135) - Used to implement CBHG module
