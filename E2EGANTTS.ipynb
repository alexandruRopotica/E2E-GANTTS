{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "E2EGANTTS.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4dSoD3OHiG-5",
        "0PdF-HRqiJXM",
        "gsFma2NQjwXJ",
        "pdTyHLSyfF9J",
        "s9JmsaR1fKnC",
        "w22ZErkza7_V",
        "H9JamBZvFzCS",
        "h_n9vIh_-XFM",
        "WHJtyoearquv",
        "lg5Eh3V2y1GT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dzpCSexVzUg"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOs78M4iV3L1"
      },
      "source": [
        "!pip install tensorflow_text\r\n",
        "!pip install tensorflow_addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUXFj5H5hfld"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import tensorflow_hub as hub\r\n",
        "import tensorflow_text as text\r\n",
        "import tensorflow_addons as tfa\r\n",
        "import numpy as np\r\n",
        "import IPython.display as ipd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRQYjkUNuMGY"
      },
      "source": [
        "# GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dSoD3OHiG-5"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PdF-HRqiJXM"
      },
      "source": [
        "### Orthogonal regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dHyeXwZiMX-"
      },
      "source": [
        "class OrthogonalRegularizer(tf.keras.regularizers.Regularizer):\r\n",
        "    def __init__(self, beta=1e-4, **kwargs):\r\n",
        "        super(OrthogonalRegularizer, self).__init__(**kwargs)\r\n",
        "        self.beta = beta\r\n",
        "\r\n",
        "    def call(self, input_tensor):\r\n",
        "        c = input_tensor.shape[-1]\r\n",
        "        x = tf.reshape(input_tensor, (-1, c))\r\n",
        "        ortho_loss = tf.matmul(x, x, transpose_a=True) * (1 - tf.eye(c))\r\n",
        "        outputs = self.beta * tf.norm(ortho_loss)\r\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsFma2NQjwXJ"
      },
      "source": [
        "### Normalized convolutional layer ✔️"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yzrTDq9j2vy"
      },
      "source": [
        "class SpectralConv1D(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, filters, kernelSize, strides=1,\r\n",
        "                padding='same', dilation=1, activation=None,\r\n",
        "                kernelInit=tf.initializers.Orthogonal,\r\n",
        "                kernelReg=OrthogonalRegularizer(), **kwargs):\r\n",
        "        super(SpectralConv1D, self).__init__(**kwargs)\r\n",
        "        self.filters = filters\r\n",
        "        self.kernelSize = kernelSize\r\n",
        "        self.strides = strides\r\n",
        "        self.padding = padding\r\n",
        "        self.dilation = dilation\r\n",
        "        self.activation = activation\r\n",
        "        self.kernelInit = kernelInit\r\n",
        "        self.kernelReg = kernelReg\r\n",
        "        self.spectralConv = tfa.layers.SpectralNormalization(\r\n",
        "            tf.keras.layers.Conv1D(filters=self.filters, kernel_size=self.kernelSize, strides=self.strides,\r\n",
        "                                padding=self.padding, dilation_rate=self.dilation, activation=self.activation,\r\n",
        "                                kernel_initializer=self.kernelInit, kernel_regularizer=self.kernelReg))\r\n",
        "  \r\n",
        "    def call(self, inputs):\r\n",
        "        outputs = self.spectralConv(inputs)\r\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqiWPJrffS0m"
      },
      "source": [
        "## Feature Net ✔️"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcWUD8Jvb9YF"
      },
      "source": [
        "class FeatureNet(tf.keras.Model):\r\n",
        "    def __init__(self, K, preprocessor, encoder, isTraining, **kwargs):\r\n",
        "        super(FeatureNet, self).__init__(**kwargs)\r\n",
        "        self.K = K\r\n",
        "        self.preprocessor = preprocessor\r\n",
        "        self.encoder = encoder\r\n",
        "        self.isTraining = isTraining\r\n",
        "        self.bert = BERT(self.preprocessor, self.encoder, self.isTraining)\r\n",
        "        self.cbhg = CBHG(self.K, self.isTraining)\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        outputs = self.bert(inputs)\r\n",
        "        outputs = self.cbhg(outputs)\r\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdTyHLSyfF9J"
      },
      "source": [
        "### BERT ✔️"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lbDNSTOVpH_"
      },
      "source": [
        "class BERT(tf.keras.Model):\r\n",
        "    def __init__(self, preprocessor, encoder, isTraining, **kwargs):\r\n",
        "        super(BERT, self).__init__(**kwargs)\r\n",
        "        self.preprocessor = preprocessor\r\n",
        "        self.encoder = encoder\r\n",
        "        self.isTraining = isTraining\r\n",
        "        self.preprocess = hub.KerasLayer(preprocessor)\r\n",
        "        self.encode = hub.KerasLayer(encoder, trainable=self.isTraining)\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        outputs = self.preprocess(inputs)\r\n",
        "        outputs = self.encode(outputs)\r\n",
        "        outputs = tf.expand_dims(outputs[\"pooled_output\"], axis=-1)\r\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9JmsaR1fKnC"
      },
      "source": [
        "### CBHG module ✔️"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SnPf7ZZHG1e"
      },
      "source": [
        "class Conv1DBank(tf.keras.Model):\r\n",
        "    def __init__(self, channels, kernelSize, activation, isTraining, **kwargs):\r\n",
        "        super(Conv1DBank, self).__init__(**kwargs)\r\n",
        "        self.channels = channels\r\n",
        "        self.kernelSize = kernelSize\r\n",
        "        self.activation = activation\r\n",
        "        self.isTraining = isTraining\r\n",
        "        self.conv1d = tf.keras.layers.Conv1D(filters=self.channels, kernel_size=self.kernelSize,\r\n",
        "                                             activation=self.activation, padding='same')\r\n",
        "        self.batchNorm = tf.keras.layers.BatchNormalization(trainable=self.isTraining)\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        outputs = self.conv1d(inputs)\r\n",
        "        outputs = self.batchNorm(outputs)\r\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtHAY3q4CTU9"
      },
      "source": [
        "class CBHG(tf.keras.Model):\r\n",
        "    def __init__(self, K, isTraining, **kwargs):\r\n",
        "        super(CBHG, self).__init__(**kwargs)\r\n",
        "        self.K = K\r\n",
        "        self.isTraining = isTraining\r\n",
        "        self.ConvBanks = [Conv1DBank(128, i, tf.nn.relu, self.isTraining) for i in range(1, self.K + 1)]\r\n",
        "        self.maxPooling = tf.keras.layers.MaxPool1D(pool_size=2, strides=1, padding='same')\r\n",
        "        self.firstProjectionConv = Conv1DBank(128, 3, tf.nn.relu, self.isTraining)\r\n",
        "        self.secondProjectionConv = Conv1DBank(128, 3, None, self.isTraining)\r\n",
        "        self.highwayNet = tf.keras.Sequential([tf.keras.layers.Dense(128, tf.nn.relu) for i in range(4)])\r\n",
        "        self.bidirectionalGRU = tf.keras.layers.Bidirectional(\r\n",
        "            tf.keras.layers.GRU(64, return_sequences=True), \r\n",
        "            backward_layer=tf.keras.layers.GRU(64, return_sequences=True, go_backwards=True))\r\n",
        "        self.encoderPreNet = tf.keras.Sequential([\r\n",
        "            tf.keras.layers.Dense(256, tf.nn.relu),\r\n",
        "            tf.keras.layers.Dropout(0.5),\r\n",
        "            tf.keras.layers.Dense(128, tf.nn.relu),\r\n",
        "            tf.keras.layers.Dropout(0.5)])\r\n",
        "        self.lastProjectionConv = Conv1DBank(1, 3, None, self.isTraining)\r\n",
        "        self.upsample = tf.keras.layers.UpSampling1D(size=400)\r\n",
        "        self.conv = tf.keras.layers.Conv1D(256, 3, padding='same')\r\n",
        "    \r\n",
        "    def call(self, inputs):\r\n",
        "        outputList = []\r\n",
        "        for convBank in self.ConvBanks:\r\n",
        "            outputList.append(convBank(inputs))\r\n",
        "        outputs = tf.keras.layers.concatenate(outputList)\r\n",
        "        outputs = self.maxPooling(outputs)\r\n",
        "        outputs = self.firstProjectionConv(outputs)\r\n",
        "        outputs = self.secondProjectionConv(outputs)\r\n",
        "        highwayOutputs = outputs + inputs\r\n",
        "        outputs = self.highwayNet(highwayOutputs)\r\n",
        "        outputs = self.bidirectionalGRU(outputs)\r\n",
        "        outputs = self.encoderPreNet(outputs)\r\n",
        "        outputs = self.lastProjectionConv(outputs)\r\n",
        "        outputs = tf.reshape(outputs, (1, 1, 256))\r\n",
        "        discOutputs = outputs\r\n",
        "        outputs = self.upsample(outputs)\r\n",
        "        genOutputs = self.conv(outputs)\r\n",
        "        return discOutputs, genOutputs\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w22ZErkza7_V"
      },
      "source": [
        "## Generatore ✔️\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIH199WIay6V"
      },
      "source": [
        "class Generator(tf.keras.Model):\r\n",
        "    def __init__(self, batchSize, **kwargs):\r\n",
        "        super(Generator, self).__init__(**kwargs)\r\n",
        "        self.batchSize = batchSize\r\n",
        "        self.preProcess = SpectralConv1D(filters=768, kernelSize=3)\r\n",
        "        self.generatorBlocks = tf.keras.Sequential([\r\n",
        "            GeneratorBlock(768, False, 1),\r\n",
        "            GeneratorBlock(768, False, 1),\r\n",
        "            GeneratorBlock(768, False, 2),\r\n",
        "            GeneratorBlock(384, False, 2),\r\n",
        "            GeneratorBlock(384, False, 2),\r\n",
        "            GeneratorBlock(384, False, 3),\r\n",
        "            GeneratorBlock(192, False, 5)])\r\n",
        "        self.postProcess = SpectralConv1D(filters=1, kernelSize=3, activation='tanh')\r\n",
        "\r\n",
        "    def call(self, inputs, noise):\r\n",
        "        outputs = self.preProcess(inputs)\r\n",
        "        for gblock in self.generatorBlocks.layers:\r\n",
        "            outputs = gblock(outputs, noise)\r\n",
        "        outputs = self.postProcess(outputs)\r\n",
        "        outputs = tf.reshape(outputs, shape=(self.batchSize, 48000))\r\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9JamBZvFzCS"
      },
      "source": [
        "### Generator block ✔️"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaHxvHw3FwlY"
      },
      "source": [
        "class GeneratorBlock(tf.keras.Model):\r\n",
        "    def __init__(self, channels, isTraining, upsampleFactor=1, **kwargs):\r\n",
        "        super(GeneratorBlock, self).__init__(**kwargs)\r\n",
        "        self.channels = channels\r\n",
        "        self.upsampleFactor = upsampleFactor\r\n",
        "        self.isTraining = isTraining\r\n",
        "        self.firstCBN = ConditionalBatchNorm(self.isTraining)\r\n",
        "        self.firstStack = tf.keras.Sequential([\r\n",
        "            SpectralConv1DTranspose(self.channels, 3, strides=self.upsampleFactor),\r\n",
        "            SpectralConv1D(self.channels, 3)])\r\n",
        "        self.secondCBN = ConditionalBatchNorm(self.isTraining)\r\n",
        "        self.firstDilatedConv = SpectralConv1D(self.channels, 3, dilation=2)\r\n",
        "        self.residualStack = tf.keras.Sequential([\r\n",
        "            SpectralConv1DTranspose(self.channels, 3, strides=self.upsampleFactor),\r\n",
        "            SpectralConv1D(self.channels, 1)])\r\n",
        "        self.thirdCBN = ConditionalBatchNorm(self.isTraining)\r\n",
        "        self.secondDilatedConv = SpectralConv1D(self.channels, 3, dilation=4)\r\n",
        "        self.fourthCBN = ConditionalBatchNorm(self.isTraining)\r\n",
        "        self.finalDilatedConv = SpectralConv1D(self.channels, 3, dilation=8)\r\n",
        "    \r\n",
        "\r\n",
        "    def call(self, inputs, noise):\r\n",
        "        outputs = self.firstCBN(inputs, noise)\r\n",
        "        outputs = self.firstStack(outputs)\r\n",
        "        outputs = self.secondCBN(outputs, noise)\r\n",
        "        outputs = self.firstDilatedConv(outputs)\r\n",
        "        residualOutputs = self.residualStack(inputs)\r\n",
        "        outputs = outputs + residualOutputs\r\n",
        "        outputs = self.thirdCBN(outputs, noise)\r\n",
        "        outputs = self.secondDilatedConv(outputs)\r\n",
        "        outputs = self.finalDilatedConv(outputs)\r\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_n9vIh_-XFM"
      },
      "source": [
        "### Conditional batch normalization + Relu ✔️"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frGKQrZ_sRo1"
      },
      "source": [
        "class ConditionalBatchNorm(tf.keras.Model):\r\n",
        "    def __init__(self, isTraining, units=1, **kwargs):\r\n",
        "        super(ConditionalBatchNorm, self).__init__(**kwargs)\r\n",
        "        self.units = units\r\n",
        "        self.isTraining = isTraining\r\n",
        "        self.randomIdx = np.random.randint(0, 128)\r\n",
        "        self.instanceNorm = tfa.layers.InstanceNormalization()\r\n",
        "        self.matrixGamma = tf.keras.layers.Dense(\r\n",
        "            self.units, trainable=self.isTraining,\r\n",
        "            kernel_initializer=tf.keras.initializers.Constant(1.0))\r\n",
        "        self.matrixBeta = tf.keras.layers.Dense(\r\n",
        "            self.units, trainable=self.isTraining,\r\n",
        "            kernel_initializer=tf.keras.initializers.Constant(0.0))\r\n",
        "        self.flatten = tf.keras.layers.Flatten()\r\n",
        "        self.relu = tf.keras.layers.ReLU()\r\n",
        "\r\n",
        "    def call(self, inputs, noise):\r\n",
        "        outputs = self.instanceNorm(inputs)\r\n",
        "        matrixGamma = self.flatten(self.matrixGamma(noise))\r\n",
        "        matrixBeta = self.flatten(self.matrixBeta(noise))\r\n",
        "        deltaGamma = matrixGamma[0][self.randomIdx]\r\n",
        "        deltaBeta = matrixBeta[0][self.randomIdx]\r\n",
        "        outputs = tf.multiply(deltaGamma, outputs) + deltaBeta\r\n",
        "        outputs = self.relu(outputs)\r\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHJtyoearquv"
      },
      "source": [
        "### Normalized transpose layer ✔️"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkGhxwiSruS0"
      },
      "source": [
        "class SpectralConv1DTranspose(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, filters, kernelSize, strides, padding='same',\r\n",
        "                kernelInit=tf.initializers.Orthogonal,\r\n",
        "                kernelReg=OrthogonalRegularizer(), **kwargs):\r\n",
        "        super(SpectralConv1DTranspose, self).__init__(**kwargs)\r\n",
        "        self.filters = filters\r\n",
        "        self.kernelSize = kernelSize\r\n",
        "        self.strides = strides\r\n",
        "        self.padding = padding\r\n",
        "        self.kernelInit = kernelInit\r\n",
        "        self.kernelReg = kernelReg\r\n",
        "        self.spectralConvTranspose = tfa.layers.SpectralNormalization(\r\n",
        "            tf.keras.layers.Conv1DTranspose(filters=self.filters, kernel_size=self.kernelSize,\r\n",
        "                                            strides=self.strides, padding=self.padding,\r\n",
        "                                            kernel_initializer=self.kernelInit, kernel_regularizer=self.kernelReg))\r\n",
        "  \r\n",
        "    def call(self, inputs):\r\n",
        "        outputs = self.spectralConvTranspose(inputs)\r\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg5Eh3V2y1GT"
      },
      "source": [
        "## Test feature net + generatore ✔️\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgb26kI7y55W"
      },
      "source": [
        "PREPROCESSOR = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\r\n",
        "ENCODER = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1\"\r\n",
        "text_input = ['This is such an amazing movie!']\r\n",
        "noise = tf.random.normal((1, 128, 1))\r\n",
        "featureNet = FeatureNet(16, PREPROCESSOR, ENCODER, False)\r\n",
        "discFeatures, genFeature = featureNet(text_input)\r\n",
        "print(discFeatures.shape, genFeature.shape)\r\n",
        "generator = Generator(1)\r\n",
        "output = generator(features, noise)\r\n",
        "output.shape\r\n",
        "#ipd.Audio(output, rate=22050)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-ENJHhVxn-S"
      },
      "source": [
        "## Discriminatore ✔️"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcDboTIk_p3x"
      },
      "source": [
        "class Discriminator(tf.keras.Model):\r\n",
        "    def __init__(self, **kwargs):\r\n",
        "        super(Discriminator, self).__init__(**kwargs)\r\n",
        "        self.uDscriminatorStack = [\r\n",
        "            UnconditionalDiscriminator(1, (5, 3)),\r\n",
        "            UnconditionalDiscriminator(2, (5, 3)),\r\n",
        "            UnconditionalDiscriminator(4, (5, 3)),\r\n",
        "            UnconditionalDiscriminator(8, (5, 3)),\r\n",
        "            UnconditionalDiscriminator(15, (2, 2))]\r\n",
        "        self.cDiscriminatorStack = [\r\n",
        "            ConditionalDiscriminator(1, (1, 5, 3, 2, 2, 2)),\r\n",
        "            ConditionalDiscriminator(2, (1, 5, 3, 2, 2)),\r\n",
        "            ConditionalDiscriminator(4, (1, 5, 3, 2, 2)),\r\n",
        "            ConditionalDiscriminator(8, (1, 5, 3)),\r\n",
        "            ConditionalDiscriminator(15, (1, 2, 2, 2))  \r\n",
        "        ]\r\n",
        "        self.flatten = tf.keras.layers.Flatten()\r\n",
        "        self.denseStack = ([tf.keras.layers.Dense(1) for i in range(5)])\r\n",
        "        \r\n",
        "    def call(self, w1Inputs, w2Inputs, w3Inputs, w4Inputs, w5Inputs, condition):\r\n",
        "        outputs = 0\r\n",
        "        windows = [w1Inputs, w2Inputs, w3Inputs, w4Inputs, w5Inputs]\r\n",
        "        for uDisc, cDisc, window, dense in zip(self.uDscriminatorStack, self.cDiscriminatorStack, windows, self.denseStack):\r\n",
        "            outputs += dense(self.flatten(uDisc(window)) + self.flatten(cDisc(window, condition)))\r\n",
        "        return outputs\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HkoPcy13wjq"
      },
      "source": [
        "### Unconditional discriminator ✔️"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpPryvQRxsz1"
      },
      "source": [
        "class UnconditionalDiscriminator(tf.keras.Model):\r\n",
        "    def __init__(self, downsampleFactor, factors, **kwargs):\r\n",
        "        super(UnconditionalDiscriminator, self).__init__(**kwargs)\r\n",
        "        self.downsampleFactor = downsampleFactor\r\n",
        "        self.factors = factors\r\n",
        "        self.reshapeNet = tf.keras.Sequential([\r\n",
        "            SpectralConv1D(filters=self.downsampleFactor, kernelSize=1),\r\n",
        "            tf.keras.layers.MaxPool1D(self.downsampleFactor, padding='same')\r\n",
        "            ])\r\n",
        "        self.dBlockStack = tf.keras.Sequential([\r\n",
        "            DiscriminatorBlock(64, 1),\r\n",
        "            DiscriminatorBlock(128, self.factors[0]),\r\n",
        "            DiscriminatorBlock(256, self.factors[1]),\r\n",
        "            DiscriminatorBlock(256, 1),\r\n",
        "            DiscriminatorBlock(256, 1)\r\n",
        "        ])\r\n",
        "        self.avgPool = tf.keras.layers.AveragePooling1D()\r\n",
        "        \r\n",
        "    def call(self, inputs):\r\n",
        "        outputs = self.reshapeNet(inputs)\r\n",
        "        outputs = self.dBlockStack(outputs)\r\n",
        "        outputs = self.avgPool(outputs)\r\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3ZBK42yFBzt"
      },
      "source": [
        "### Conditional discriminator ✔️"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7dDEt9sFGC8"
      },
      "source": [
        "class ConditionalDiscriminator(tf.keras.Model):\r\n",
        "    def __init__(self, downsampleFactor, factors, **kwargs):\r\n",
        "        super(ConditionalDiscriminator, self).__init__(**kwargs)\r\n",
        "        self.downsampleFactor = downsampleFactor\r\n",
        "        self.factors = factors\r\n",
        "        dblockList = []\r\n",
        "        dblockSize = 64\r\n",
        "        self.reshape = tf.keras.Sequential([\r\n",
        "            SpectralConv1D(filters=self.downsampleFactor, kernelSize=1),\r\n",
        "            tf.keras.layers.MaxPool1D(self.downsampleFactor, padding='same')])\r\n",
        "        for i in range(len(self.factors) - 1):\r\n",
        "            dblockList.append(DiscriminatorBlock(dblockSize, self.factors[i]))\r\n",
        "            dblockSize = dblockSize * 2\r\n",
        "        self.dblockStack = tf.keras.Sequential(dblockList)\r\n",
        "        self.condDBlock = ConditionalDBlock(dblockSize, self.factors[-1])\r\n",
        "        self.finalDBlocks = tf.keras.Sequential([\r\n",
        "            DiscriminatorBlock(dblockSize, 1),\r\n",
        "            DiscriminatorBlock(dblockSize, 1)])\r\n",
        "        self.avgPool = tf.keras.layers.AveragePooling1D()\r\n",
        "        \r\n",
        "    def call(self, inputs, condition):\r\n",
        "        outputs = self.reshape(inputs)\r\n",
        "        outputs = self.dblockStack(outputs)\r\n",
        "        outputs = self.condDBlock(outputs, condition)\r\n",
        "        outputs = self.finalDBlocks(outputs)\r\n",
        "        outputs = self.avgPool(outputs)\r\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EM1bYB_Xur2"
      },
      "source": [
        "#### Conditional dblock ✔️"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKTmObkOXwwP"
      },
      "source": [
        "class ConditionalDBlock(tf.keras.Model):\r\n",
        "    def __init__(self, filters, downsampleFactor, **kwargs):\r\n",
        "        super(ConditionalDBlock, self).__init__(**kwargs)\r\n",
        "        self.filters = filters\r\n",
        "        self.downsampleFactor = downsampleFactor\r\n",
        "        self.firstStack = tf.keras.Sequential([\r\n",
        "            tf.keras.layers.MaxPool1D(self.downsampleFactor, padding='same'),\r\n",
        "            tf.keras.layers.ReLU(),\r\n",
        "            SpectralConv1D(filters=self.filters, kernelSize=3)])\r\n",
        "        self.featureConv = SpectralConv1D(filters=self.filters, kernelSize=1)\r\n",
        "        self.secondStack = tf.keras.Sequential([\r\n",
        "            tf.keras.layers.ReLU(),\r\n",
        "            SpectralConv1D(filters=self.filters, kernelSize=3, dilation=2)])\r\n",
        "        self.residualStack = tf.keras.Sequential([\r\n",
        "            SpectralConv1D(filters=self.filters, kernelSize=1),\r\n",
        "            tf.keras.layers.MaxPool1D(self.downsampleFactor, padding='same')\r\n",
        "            ])\r\n",
        "\r\n",
        "    def call(self, inputs, condition):\r\n",
        "        outputs = self.firstStack(inputs)\r\n",
        "        featureOutputs = self.featureConv(condition)\r\n",
        "        outputs = outputs + featureOutputs\r\n",
        "        outputs = self.secondStack(outputs)\r\n",
        "        residualOutputs = self.residualStack(inputs)\r\n",
        "        outputs = outputs + residualOutputs\r\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LKbyyqt33Sm"
      },
      "source": [
        "### Discriminator block ✔️"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23ppTnRB395T"
      },
      "source": [
        "class DiscriminatorBlock(tf.keras.Model):\r\n",
        "    def __init__(self, filters, downsampleFactor, **kwargs):\r\n",
        "        super(DiscriminatorBlock, self).__init__(**kwargs)\r\n",
        "        self.filters = filters\r\n",
        "        self.downsampleFactor = downsampleFactor\r\n",
        "        self.stack = tf.keras.Sequential([\r\n",
        "            tf.keras.layers.MaxPool1D(self.downsampleFactor, padding='same'),\r\n",
        "            tf.keras.layers.ReLU(),\r\n",
        "            SpectralConv1D(filters=self.filters, kernelSize=3, activation=tf.nn.relu),\r\n",
        "            SpectralConv1D(filters=self.filters, kernelSize=3, activation=tf.nn.relu, dilation=2)])\r\n",
        "        self.residualStack = tf.keras.Sequential([\r\n",
        "            SpectralConv1D(filters=self.filters, kernelSize=3),\r\n",
        "            tf.keras.layers.MaxPool1D(self.downsampleFactor, padding='same')])\r\n",
        "        \r\n",
        "    def call(self, inputs):\r\n",
        "        outputs = self.stack(inputs)\r\n",
        "        residualOutputs = self.residualStack(inputs)\r\n",
        "        outputs = residualOutputs + outputs\r\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myDY7qONyUhe"
      },
      "source": [
        "## Test discriminatore ✔️"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5kaNwUTsuud"
      },
      "source": [
        "w240 = tf.random.normal((1, 240, 1))\r\n",
        "w480 = tf.random.normal((1, 480, 1))\r\n",
        "w960 = tf.random.normal((1, 960, 1))\r\n",
        "w1920 = tf.random.normal((1, 1920, 1))\r\n",
        "w3600 = tf.random.normal((1, 3600, 1))\r\n",
        "f = tf.random.normal((1, 1, 256))\r\n",
        "model = Discriminator()\r\n",
        "output = model(w240, w480, w960, w1920, w3600, f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}